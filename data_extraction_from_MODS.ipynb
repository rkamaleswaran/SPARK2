{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1032ecae-8139-497c-b516-b40bf3e57f71",
   "metadata": {},
   "source": [
    "# Data Extraction from MODS folder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ae86c4-d611-4aca-9d76-e26d91ce4c35",
   "metadata": {},
   "source": [
    "*note* \n",
    "- Data extraction is performed in BMI cluster which runs in\n",
    "    - python: 3.6.12.final.0\n",
    "    - pandas: 1.1.4\n",
    "- The installed libraries ver. in BMI cluster is different from what VM has. Thus, some parts of the scripts are modified to accommodate this. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a936d7ca-2117-47a4-ab48-99fb24aece9f",
   "metadata": {},
   "source": [
    "The following notebook outputs data creates a supertable in hourly bins\n",
    "\n",
    "1. Encounters\n",
    "2. Sepsis Label Data\n",
    "    - merge sepsis label data\n",
    "    - filter 2021 data and define cohort csns\n",
    "3. Vitals\n",
    "4. Labs\n",
    "5. GCS\n",
    "6. Demographics\n",
    "7. Fluids\n",
    "8. Mechanical Ventilation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3058da96-59c0-4100-86cc-9d3e0a37a01b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from datetime import datetime\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import sys \n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "pd.options.display.max_columns = 500\n",
    "pd.options.display.max_rows = 500\n",
    "pd.options.display.float_format = '{:,.4f}'.format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cad61bb6-8027-4e19-9948-965cc29ef7e9",
   "metadata": {},
   "source": [
    "## Extraction Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "044bfbd6-3104-41c3-90fd-d8ed3d07d67c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def import_dsv(directories, fetch_cols = [], thresholds = [], csns = [], pat_ids = [], save_dir = \"\"):\n",
    "    \n",
    "    total = pd.DataFrame()\n",
    "    processed_cols = []\n",
    "    if len(thresholds)!=0:\n",
    "        process_cols = list(thresholds.keys())\n",
    "    else: process_cols = []\n",
    "        \n",
    "    \n",
    "    # read in for each directory\n",
    "    for directory in directories:\n",
    "        \n",
    "        chunksize = 10**5\n",
    "\n",
    "        t = int(os.path.getsize(directory)/chunksize) + 1\n",
    "        \n",
    "        with tqdm(total = t, file = sys.stdout) as pbar:\n",
    "            \n",
    "            # read in by chunk size\n",
    "            for i, chunk in enumerate(pd.read_csv(directory, sep=\"|\", chunksize=chunksize, low_memory=False)):\n",
    "                \n",
    "                # if pat_ids and csns are specifed, just extract those patients. Otherwise, extract all patients.\n",
    "                if len(pat_ids)!=0:\n",
    "                    chunk = chunk[chunk.pat_id.isin(pat_ids)]\n",
    "                if len(csns)!= 0:\n",
    "                    chunk = chunk[chunk.csn.isin(csns)]\n",
    "                \n",
    "                # extract only specified columns. Otherwise, extract all columns.\n",
    "                if len(fetch_cols) != 0:\n",
    "                    chunk = chunk[fetch_cols]\n",
    "               \n",
    "                # if there's anything to preprocess- data cleaning w/ thresholds\n",
    "                for feature in process_cols:\n",
    "                    chunk.loc[:,feature] = chunk[feature].replace(r'\\>|\\<|\\%|\\/|\\s','',regex=True)\n",
    "                    chunk.loc[:,feature] = pd.to_numeric(chunk[feature], errors='coerce')\n",
    "                    mask_ind = (chunk[feature] < thresholds[feature][1]) & (chunk[feature] > thresholds[feature][0])\n",
    "                    chunk.loc[~mask_ind, feature]  = np.nan\n",
    "\n",
    "                total = total.append(chunk)\n",
    "\n",
    "                pbar.set_description('Importing: %d' % (1 + i))\n",
    "                pbar.update(1)\n",
    "    \n",
    "    print(\"extraction complete\")\n",
    "    \n",
    "    if len(save_dir) != 0:\n",
    "        total.to_csv(save_dir, index = False)\n",
    "    \n",
    "    return total.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b1f674cf-1947-46a2-9d02-a4cbf56af7c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def import_labs(directories, thresholds = [], csns = [], pat_ids = [], loinc_dir = \"\", save_dir = \"\"):\n",
    "    \n",
    "    fetch_cols = [\"pat_id\", \"csn\", \"collection_time\", \"component\", \"component_id\", \"loinc_code\", \"lab_result\"]\n",
    "    total = pd.DataFrame()\n",
    "    loinc_codes = 0\n",
    "    any_codes = []\n",
    "    specific_codes = []\n",
    "    if len(thresholds)!=0:\n",
    "        process_cols = list(thresholds.keys())\n",
    "    else: process_cols = []\n",
    "        \n",
    "    if len(loinc_dir) > 0 :  \n",
    "        loinc_codes = pd.read_csv(loinc_dir)\n",
    "        any_codes = list(loinc_codes[loinc_codes.isna().any(axis = 1)][\"loinc_code\"])\n",
    "        codes = list(loinc_codes[\"component_id\"])\n",
    "        specific_codes = list(loinc_codes[~loinc_codes.isna().any(axis = 1)][\"loinc_code\"])\n",
    "    \n",
    "    # read in for each directory\n",
    "    for directory in directories:\n",
    "        \n",
    "        chunksize = 10**5\n",
    "\n",
    "        t = int(os.path.getsize(directory)/chunksize) + 1\n",
    "        \n",
    "        with tqdm(total = t, file = sys.stdout) as pbar:\n",
    "            \n",
    "            # read in by chunk size\n",
    "            for i, chunk in enumerate(pd.read_csv(directory, sep=\"|\", chunksize=chunksize, low_memory=False)):\n",
    "                \n",
    "                # if pat_ids and csns are specifed, just extract those patients. Otherwise, extract all patients.\n",
    "                if len(pat_ids)!=0:\n",
    "                    chunk = chunk[chunk.pat_id.isin(pat_ids)]\n",
    "                if len(csns)!= 0:\n",
    "                    chunk = chunk[chunk.csn.isin(csns)]\n",
    "  \n",
    "                # for labs only\n",
    "                if len(any_codes) + len(specific_codes) != 0:\n",
    "                    chunk1 = chunk[chunk[\"component_id\"].isin(codes)]\n",
    "                    chunk1 = chunk1[chunk1[\"loinc_code\"].isin(specific_codes)]\n",
    "                    chunk2 = chunk[chunk[\"loinc_code\"].isin(any_codes)]\n",
    "                    chunk = pd.concat([chunk1, chunk2])\n",
    "\n",
    "                total = total.append(chunk)\n",
    "                \n",
    "                pbar.set_description('Importing: %d' % (1 + i))\n",
    "                pbar.update(1)  \n",
    "    \n",
    "    if len(loinc_dir) > 0:    \n",
    "        labs_cleaned = total.merge(loinc_codes, on = \"loinc_code\", how = \"left\")\n",
    "    else:\n",
    "        labs_cleaned[\"FEATURE\"] = total[\"component\"]\n",
    "        \n",
    "    labs_cleaned = labs_cleaned[[\"pat_id\", \"csn\", \"collection_time\", \"FEATURE\", \"lab_result\"]]\n",
    "    labs_cleaned[\"lab_result\"] = labs_cleaned[\"lab_result\"].replace(r'\\>|\\<|\\%|\\/|\\s','',regex=True)\n",
    "    labs_cleaned[\"lab_result\"] = pd.to_numeric(labs_cleaned[\"lab_result\"], errors='coerce')\n",
    "    piv_new_labs = labs_cleaned.pivot_table(index=['csn', \"pat_id\", \"collection_time\"], columns='FEATURE', values='lab_result')\n",
    "    piv_new_labs = piv_new_labs.reset_index()\n",
    "\n",
    "\n",
    "    for feature in process_cols:\n",
    "        mask_ind = (piv_new_labs[feature] < thresholds[feature][1]) & (piv_new_labs[feature] > thresholds[feature][0])\n",
    "        piv_new_labs.loc[~mask_ind, feature]  = np.nan\n",
    "                \n",
    "    \n",
    "    print(\"extraction complete\")\n",
    "    \n",
    "    if len(save_dir) > 0:\n",
    "        piv_new_labs.to_csv(save_dir, index = False)\n",
    "    \n",
    "    return piv_new_labs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d1f5318c-0b52-41b6-82ce-8397c71ba287",
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_csv(directories, fetch_cols = [], thresholds = [], csns = [], pat_ids = [], save_dir = \"\"):\n",
    "    \n",
    "    total = pd.DataFrame()\n",
    "    processed_cols = []\n",
    "    if len(thresholds)!=0:\n",
    "        process_cols = list(thresholds.keys())\n",
    "    else: process_cols = []\n",
    "        \n",
    "    \n",
    "    # read in for each directory\n",
    "    for directory in directories:\n",
    "        \n",
    "        chunksize = 10**5\n",
    "\n",
    "        t = int(os.path.getsize(directory)/chunksize) + 1\n",
    "        \n",
    "        with tqdm(total = t, file = sys.stdout) as pbar:\n",
    "            \n",
    "            # read in by chunk size\n",
    "            for i, chunk in enumerate(pd.read_csv(directory, chunksize=chunksize, low_memory=False)):\n",
    "                \n",
    "                # if pat_ids and csns are specifed, just extract those patients. Otherwise, extract all patients.\n",
    "                if len(pat_ids)!=0:\n",
    "                    chunk = chunk[chunk.pat_id.isin(pat_ids)]\n",
    "                if len(csns)!= 0:\n",
    "                    chunk = chunk[chunk.CSN.isin(csns)]\n",
    "                \n",
    "                # extract only specified columns. Otherwise, extract all columns.\n",
    "                if len(fetch_cols) != 0:\n",
    "                    chunk = chunk[fetch_cols]\n",
    "               \n",
    "                # if there's anything to preprocess- data cleaning w/ thresholds\n",
    "                for feature in process_cols:\n",
    "                    chunk.loc[:,feature] = chunk[feature].replace(r'\\>|\\<|\\%|\\/|\\s','',regex=True)\n",
    "                    chunk.loc[:,feature] = pd.to_numeric(chunk[feature], errors='coerce')\n",
    "                    mask_ind = (chunk[feature] < thresholds[feature][1]) & (chunk[feature] > thresholds[feature][0])\n",
    "                    chunk.loc[~mask_ind, feature]  = np.nan\n",
    "\n",
    "                total = total.append(chunk)\n",
    "\n",
    "                pbar.set_description('Importing: %d' % (1 + i))\n",
    "                pbar.update(1)\n",
    "    \n",
    "    print(\"extraction complete\")\n",
    "    \n",
    "    if len(save_dir) != 0:\n",
    "        total.to_csv(save_dir, index = False)\n",
    "    \n",
    "    return total.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b3dc2d0-92d3-46e0-a20c-1a4f0eee826d",
   "metadata": {},
   "source": [
    "## 1. Read Encounters\n",
    "Include patients from EUH Midtown, Emory University Hospital, Emory Saint Josephs Hospital, and Emory Johns Creek Hospital"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "38c28202-dc6b-46db-86ef-6854d54e5f8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing: 3:   1%|          | 3/426 [00:03<08:07,  1.15s/it]\n",
      "Importing: 3:   1%|          | 3/425 [00:03<08:12,  1.17s/it]\n",
      "extraction complete\n"
     ]
    }
   ],
   "source": [
    "f = [\"/labs/kamaleswaranlab/MODS/Data/Emory_Data/em_data/2020/CJSEPSIS_ENCOUNTER_2020.dsv\",\n",
    "     \"/labs/kamaleswaranlab/MODS/Data/Emory_Data/em_data/2021/CJSEPSIS_ENCOUNTER_2021.dsv\"]\n",
    "fetch_cols = [\"pat_id\", \"csn\", \"age\", \"ed_presentation_time\", \"hospital_admission_date_time\", \n",
    "              \"hospital_discharge_date_time\", \"facility_nm\", \"discharge_to\"]\n",
    "total_enc = import_dsv(directories = f, fetch_cols = fetch_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b7b3d8bd-f66b-4a69-9669-7b54adadcc15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EUH Midtown                     150655\n",
       "Emory University Hospital       124261\n",
       "Emory Saint Josephs Hospital     89666\n",
       "Emory Johns Creek Hospital       59531\n",
       "Name: facility_nm, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_enc.facility_nm.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3c162e36-e26f-4712-9310-54b95155307a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess encounter data\n",
    "\n",
    "# Change facility name to abbreviated names\n",
    "facility_map = {\"Emory University Hospital\": \"EUH\", \n",
    "                'Emory Johns Creek Hospital': \"EJCH\",\n",
    "                'Emory Saint Josephs Hospital': \"ESJH\", \n",
    "                'EUH Midtown': \"EUHM\"}\n",
    "total_enc = total_enc.replace({\"facility_nm\": facility_map})\n",
    "\n",
    "# Change datatype\n",
    "total_enc[\"hospital_admission_date_time\"] = pd.to_datetime(total_enc[\"hospital_admission_date_time\"])\n",
    "# Create column for year\n",
    "total_enc[\"year\"] = total_enc[\"hospital_admission_date_time\"].dt.year\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2f826fb5-7f12-448e-beae-a20079e71c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter only legacy hospitals\n",
    "legacy = [\"EUH\", \"EJCH\", \"EUHM\", \"ESJH\"]\n",
    "total_enc = total_enc[total_enc[\"facility_nm\"].isin(legacy)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84795722-7c1b-415a-9b86-85ca3b0e9e06",
   "metadata": {},
   "source": [
    "## 2. Read Sepsis Label Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7d8bf0e5-3a7c-471b-a317-81c564ee043e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are 6298 csns from EHR data\n"
     ]
    }
   ],
   "source": [
    "ehr = pd.read_csv(\"../real_time_sepsis_development/real_time_data/ehr_data.csv\")\n",
    "ehr = ehr.rename(columns ={\"Encounter\": \"csn\"})\n",
    "\n",
    "ehr[\"hospital_admission_date\"] = pd.to_datetime(ehr[\"hospital_admission_date\"])\n",
    "ehr[\"time_zero\"] = pd.to_datetime(ehr[\"time_zero\"])\n",
    "\n",
    "ehr = ehr[~ehr.time_zero.isna()]\n",
    "ehr = ehr.sort_values(by = \"time_zero\")\n",
    "ehr = ehr.drop_duplicates(subset = [\"csn\"], keep = \"first\")\n",
    "\n",
    "#csns = ehr.csn.unique()\n",
    "print(\"there are %i csns from EHR data\" % len(ehr))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f73c197a-f25e-4d79-abfc-4742a9b90e31",
   "metadata": {},
   "source": [
    "### 2.1 Merge Sepsis Label Data to Encounters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cdeaf6ca-b03b-4c28-8bdc-93c39bf665a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of csns: 252003\n"
     ]
    }
   ],
   "source": [
    "merged_times = total_enc.merge(ehr, how = \"left\", on = [\"csn\", \"facility_nm\"])\n",
    "merged_times = merged_times.drop([\"hospital_admission_date\", \"hospital_discharge_date\", \"facility_nm\"], axis = 1)\n",
    "merged_times = merged_times.drop_duplicates(subset = [\"csn\"])\n",
    "\n",
    "times = merged_times.copy()\n",
    "times = times.rename(columns = {\"time_zero\": \"t_sepsis3\"})\n",
    "times = times.sort_values(\"hospital_admission_date_time\")\n",
    "\n",
    "# we only want first encounter per patient\n",
    "keep_csns = list(times.groupby(\"pat_id\").csn.first())\n",
    "times = times[times.csn.isin(keep_csns)]\n",
    "print(\"total number of csns:\" , len(keep_csns))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0387bd9a-b4df-49b7-82e6-40354e722bfe",
   "metadata": {},
   "source": [
    "### 2.2 Filter 2021 data only & define all csns to keep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "41451fc9-34b1-4fa8-92d7-1f4726712552",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of sepsis patients from 2021:  1736\n",
      "number of non-sepsis patients from 2021:  111365\n",
      "total number of encounters in 2021 cohort:  113101\n"
     ]
    }
   ],
   "source": [
    "\n",
    "times = times[times.year == 2021]\n",
    "sepsis_2021 = list(times[~times.t_sepsis3.isna()].csn)\n",
    "nosepsis_2021 = list(times[times.t_sepsis3.isna()].csn)\n",
    "print(\"number of sepsis patients from 2021: \", len(sepsis_2021))\n",
    "print(\"number of non-sepsis patients from 2021: \",len(nosepsis_2021))\n",
    "\n",
    "csns = sepsis_2021 + nosepsis_2021\n",
    "pat_ids = list(times.pat_id)\n",
    "\n",
    "print(\"total number of encounters in 2021 cohort: \", len(csns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9fabfd47-bbc3-42b2-8914-9c7e8e764164",
   "metadata": {},
   "outputs": [],
   "source": [
    "times.to_csv(\"times2021.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbe1b592-8e6d-4d48-a7a2-2d74f38be5ff",
   "metadata": {},
   "source": [
    "# 3. Vitals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ad084a8b-e924-4bf0-afb2-953779932d63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing: 74:   1%|▏         | 74/5881 [04:28<5:51:24,  3.63s/it]\n",
      "extraction complete\n"
     ]
    }
   ],
   "source": [
    "# define directories\n",
    "vitals_directories = [ \"/labs/kamaleswaranlab/MODS/Data/Emory_Data/em_data/2021/CJSEPSIS_VITALS_2021.dsv\"]\n",
    "# define thresholds\n",
    "vitals_thresh = { \"pulse\": (0,250),\n",
    "                 \"spo2\": (0,100),\n",
    "                 \"temperature\": (25,45),\n",
    "                 \"sbp_cuff\": (0,260),\n",
    "                 \"sbp_line\": (0,260),\n",
    "                 \"dbp_cuff\": (0, 220),\n",
    "                 \"dbp_line\": (0, 220),\n",
    "                 \"map_cuff\": (0,260),\n",
    "                 \"map_line\": (0,260),\n",
    "                 'unassisted_resp_rate': (0,80),\n",
    "                 'end_tidal_co2': (0, 60),\n",
    "                \"o2_flow_rate\": (0, 1000000),\n",
    "                \"height_cm\": (0, 230),\n",
    "                \"daily_weight_kg\": (0,300)}\n",
    "\n",
    "# define columns to extract: always include ['pat_id', 'csn', 'recorded_time']\n",
    "fetch_cols = ['pat_id', 'csn', 'recorded_time', 'o2_device'] + list(vitals_thresh.keys())\n",
    "\n",
    "#import\n",
    "vitals = import_dsv(directories = vitals_directories, fetch_cols = fetch_cols, thresholds = vitals_thresh, csns = csns, pat_ids = pat_ids)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a8bc13-97fd-46e3-89fa-06d98f0f7867",
   "metadata": {},
   "source": [
    "### 3.1 Vitals preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0dfc6551-ebb0-4e6e-b028-cc75b225454d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace unknown line values with cuff (giving higher priority to line)\n",
    "vitals[\"sbp_line\"] = vitals[\"sbp_line\"].fillna(vitals[\"sbp_cuff\"])\n",
    "vitals[\"map_line\"] = vitals[\"map_line\"].fillna(vitals[\"map_cuff\"])\n",
    "vitals.drop([\"sbp_cuff\", \"dbp_cuff\", \"map_cuff\"], axis = 1, inplace = True)\n",
    "\n",
    "# replace naming\n",
    "vitals_rename = { \"pulse\": \"HR\",\n",
    "                 \"spo2\": \"O2Sat\",\n",
    "                 \"temperature\": \"Temp\",\n",
    "                 \"sbp_line\": \"SBP\",\n",
    "                 \"map_line\": \"MAP\",\n",
    "                 \"dbp_line\": \"DBP\",\n",
    "                 'unassisted_resp_rate': \"Resp\",\n",
    "                 'end_tidal_co2': \"EtCO2\"}\n",
    "vitals = vitals.rename(columns = vitals_rename)\n",
    "# convert datatype\n",
    "vitals[\"recorded_time\"] = pd.to_datetime(vitals[\"recorded_time\"], format = \"%m/%d/%Y %H:%M:%S\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "84bb7e2e-2883-4e22-add5-db9412cd20e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "room_air = ['Room air', \n",
    "            'O2 not needed, Room air', \n",
    "            'Room air, Other: patient not wearing O2; repeatedly places O2 on forehead',\n",
    "            'O2 standby, equipment at bedside, Room air',\n",
    "            'O2 standby, equipment at bedside',\n",
    "            'O2 standby, equipment at bedside, O2 not needed, Room air',\n",
    "            'Room air, Other: walking',\n",
    "            'Room air, Other: ambulated ed hallways',\n",
    "            'Room air, Other: ambulatory',\n",
    "            'Room air, Other: walking', \n",
    "            'Room air, Other:', \n",
    "            'Room air, Other: ambulation pulse ox',\n",
    "            'Room air, Other: while ambulating on RA', \n",
    "            'Room air, Other: ambulatory sat', \n",
    "            'Room air, Other: AMBULATORY', \n",
    "            'Room air, Other: during ambulation',\n",
    "            'Room air, Other: ambulatory saturation',\n",
    "            'Room air, Other: on exertion',\n",
    "            'Room air, Other: ambulatory pulse ox', \n",
    "            'Room air, Other: walking saturation of 91-93%', \n",
    "            'Room air, Other: ambulatory O2 sat',\n",
    "            'Room air, Other: with ambulation',\n",
    "            'Room air, Other: while ambulatory',\n",
    "            'Room air, Other: when ambulating',\n",
    "            'Room air, Other: pt smokes',\n",
    "            'Room air, Other: with pt moving from wheelchair to bed',\n",
    "            'Room air, Other: walk test',\n",
    "            'Date\\\\Time Correction']\n",
    "            \n",
    "vitals.loc[~vitals.o2_device.isin(room_air), \"o2_supp\"] = 1\n",
    "vitals.loc[vitals.o2_device.isna(), \"o2_supp\"] = np.nan\n",
    "vitals[\"o2_supp\"] = vitals.o2_supp.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "76ebe0e0-f48d-4b48-9374-ec46987f9e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "vitals.to_csv(\"vitals_2021.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a68856fe-9135-4fa8-bf5e-0bda522cf2a4",
   "metadata": {},
   "source": [
    "## 4. Labs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a4d14467-f815-4d60-90d6-f10a2e345862",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing: 171:   1%|          | 171/27817 [07:07<19:12:52,  2.50s/it]\n",
      "extraction complete\n"
     ]
    }
   ],
   "source": [
    "# define directories\n",
    "labs_directories = [\"/labs/kamaleswaranlab/MODS/Data/Emory_Data/em_data/2021/CJSEPSIS_LABS_2021.dsv\"]\n",
    "# define thresholds\n",
    "labs_thresh = { \"pH\": (6.7, 8),\n",
    "              \"PaCO2\": (15, 150),\n",
    "              \"SaO2\": (0,100),\n",
    "              \"AST\": (0, 10000),\n",
    "              \"BUN\": (0,200),\n",
    "              \"Alkalinephos\": (0, 10000),\n",
    "              \"Calcium\": (0,20),\n",
    "              \"Chloride\": (60,150),\n",
    "              \"Creatinine\": (0, 15),\n",
    "              \"Bilirubin_direct\": (0,30),\n",
    "              \"Glucose\": (0, 1200),\n",
    "              \"Lactate\": (0,20),\n",
    "              \"Magnesium\": (0,10), \n",
    "              \"Phosphate\": (0,20),\n",
    "              \"Potassium\": (0,10),\n",
    "              \"Bilirubin_total\": (0,30),\n",
    "              \"TroponinI\": (0,15),\n",
    "              \"Hct\": (0, 75),\n",
    "               \"Hgb\": (0,25),\n",
    "               \"PTT\": (0,150),\n",
    "               \"WBC\": (0,150),\n",
    "               \"Fibrinogen\": (0,1000),\n",
    "               \"Platelets\": (0,1000),\n",
    "               \"Albumin\": (0,20),\n",
    "               \"Anion_Gap\": (0,100),\n",
    "               \"INR\": (0,100),\n",
    "               \"MCHC\": (0,100),\n",
    "               \"MCH\": (0, 100),\n",
    "               \"MPV\": (0, 100),\n",
    "               \"Phosphorus\": (0, 100),\n",
    "               \"PT\": (0, 300),\n",
    "               \"Protein\": (0,20),\n",
    "               \"RBC\": (0,20),\n",
    "               \"RDW-CV\": (0,200),\n",
    "               \"RDW-SD\": (0, 200)\n",
    "              }\n",
    "\n",
    "# import data\n",
    "labs = import_labs(directories = labs_directories, thresholds = labs_thresh, csns = csns, \n",
    "                   pat_ids = pat_ids, loinc_dir = \"../real_time_sepsis_development/real_time_data/emory_lab_loinc (3).csv\")\n",
    "\n",
    "# preprocess\n",
    "# use uniform column name for times\n",
    "labs = labs.rename(columns = {\"collection_time\": \"recorded_time\"})\n",
    "# change recorded time datatype\n",
    "labs[\"recorded_time\"] = pd.to_datetime(labs[\"recorded_time\"], format = \"%m/%d/%Y %H:%M:%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "222cdc22-7845-4780-b516-d7bd2305e549",
   "metadata": {},
   "outputs": [],
   "source": [
    "labs.to_csv(\"labs_2021.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a95ebed-d0d2-4c0b-91ac-14cf9b8db588",
   "metadata": {},
   "source": [
    "## 5. GCS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7d7dffb4-d5d2-4aa8-b980-19bde4fd424e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing: 11:   2%|▏         | 11/644 [00:03<03:21,  3.14it/s]\n",
      "extraction complete\n"
     ]
    }
   ],
   "source": [
    "# specify directory\n",
    "gcs_dir = [\"/labs/kamaleswaranlab/MODS/Data/Emory_Data/em_data/2021/CJSEPSIS_GCS_2021.dsv\"]\n",
    "\n",
    "# specify columns: always include ['pat_id', 'csn', 'recorded_time']\n",
    "fetch_cols = [\"pat_id\", \"csn\", \"recorded_time\", \"gcs_total_score\"]\n",
    "\n",
    "gcs = import_dsv(directories = gcs_dir, fetch_cols = fetch_cols, pat_ids = pat_ids, csns = csns)\n",
    "\n",
    "# preprocess\n",
    "#gcs[\"recorded_time\"] = pd.to_datetime(gcs[\"recorded_time\"])\n",
    "gcs[\"recorded_time\"] = gcs[\"recorded_time\"].apply(lambda x: datetime.strptime(x,\"%m/%d/%Y %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b534eca6-c3fe-411c-bfc0-be8ff84aed3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "gcs.to_csv(\"GCS2021.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cab18ee-c1b9-4e88-8f04-b22ad7f4a9b8",
   "metadata": {},
   "source": [
    "## 6. Demographics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2d620f4d-b832-487d-927a-434430533cec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing: 3:   1%|          | 3/308 [00:02<03:36,  1.41it/s]\n",
      "Importing: 3:   1%|          | 3/364 [00:01<03:29,  1.73it/s]\n",
      "Importing: 3:   1%|          | 3/282 [00:01<03:00,  1.54it/s]\n",
      "Importing: 3:   1%|          | 3/279 [00:01<02:15,  2.04it/s]\n",
      "extraction complete\n"
     ]
    }
   ],
   "source": [
    "# specify directory\n",
    "demo_dir = [\"/labs/kamaleswaranlab/MODS/Data/Emory_Data/em_data/2018/CJSEPSIS_DEMOGRAPHICS_2018.dsv\",\n",
    "            \"/labs/kamaleswaranlab/MODS/Data/Emory_Data/em_data/2019/CJSEPSIS_DEMOGRAPHICS_2019.dsv\",\n",
    "    \"/labs/kamaleswaranlab/MODS/Data/Emory_Data/em_data/2020/CJSEPSIS_DEMOGRAPHICS_2020.dsv\",\n",
    "            \"/labs/kamaleswaranlab/MODS/Data/Emory_Data/em_data/2021/CJSEPSIS_DEMOGRAPHICS_2021.dsv\"]\n",
    "\n",
    "# specify columns: always include pat_id\n",
    "fetch_cols = [\"pat_id\", \"race\", \"gender\", \"ethnicity\"]\n",
    "\n",
    "demographics = import_dsv(directories = demo_dir, fetch_cols = fetch_cols, pat_ids = pat_ids)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1623de66-e353-4ce5-9576-af9d7886c2cf",
   "metadata": {},
   "source": [
    "### 6.1 Demographics Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "49ee693d-62f9-4450-8ddb-aa6038c9ea7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "demographics[\"race\"] = demographics[\"race\"].str.strip()\n",
    "demographics[\"gender\"] = demographics[\"gender\"].str.strip()\n",
    "dem = demographics.drop_duplicates(subset = [\"pat_id\", \"race\", \"gender\"])\n",
    "\n",
    "race_code = {'Unknown, Unavailable or Unreported': 0,\n",
    "            'African American  or Black': 3,\n",
    "            'Caucasian or White':2, \n",
    "            'Native Hawaiian or Other Pacific Islander':0,\n",
    "            'American Indian or Alaskan Native':0,\n",
    "            'Multiple': 0, \n",
    "            'Asian': 1,\n",
    "            'Patient Declines': 0, \n",
    "             'Not Recorded': 0, \n",
    "             'Alaskan Native': 0}\n",
    "\n",
    "gender_code = {\"Female\": 1, \"Male\": 0}\n",
    "dem = dem.replace({\"gender\": gender_code})\n",
    "dem = dem.replace({\"race\": race_code})\n",
    "\n",
    "race_gender = dem.groupby('pat_id').sum().reset_index()\n",
    "\n",
    "race_gender = race_gender.rename(columns = {\"gender\": \"is_female\"})\n",
    "\n",
    "race_gender.loc[race_gender.race == 0, \"is_other\"] =1\n",
    "race_gender.loc[race_gender.race == 1, \"is_asian\"] =1\n",
    "race_gender.loc[race_gender.race == 2, \"is_white\"] =1\n",
    "race_gender.loc[race_gender.race == 3, \"is_black\"] =1\n",
    "\n",
    "race_gender.drop([\"race\"], axis =1, inplace = True)\n",
    "race_gender = race_gender.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "64811c5e-5fae-4aca-b8d5-e52a740413e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "race_gender.to_csv(\"race_gender_2021.csv\", index= False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1202f0cb-529a-439a-97ce-551cae2d6bfe",
   "metadata": {},
   "source": [
    "## 7. Fluids\n",
    "fluids data is stored in csv not dsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d9369565-7b8e-4aae-be38-c6939ba164f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing: 1415:   1%|          | 1415/135463 [27:58<44:10:02,  1.19s/it] \n",
      "extraction complete\n"
     ]
    }
   ],
   "source": [
    "fluids = import_csv(directories = [\"/labs/kamaleswaranlab/MODS/CJSEPSIS_INOUTS_ALL.csv\"], csns = csns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c719541a-0fd0-4508-9364-25e98ce0c3be",
   "metadata": {},
   "source": [
    "### 7.1 Urine Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3f304d0c-c633-42f1-b17b-8e1035e4cd9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "urine = ['Urine Voided mL','Urine Straight Catheter Ouput']\n",
    "urine_output = fluids[fluids.STRUCTURED_RESULT_TYPE.isin(urine)]\n",
    "\n",
    "# column name change\n",
    "urine_output = urine_output.rename(columns = {\"CSN\": \"csn\", \"SERVICE_TIMESTAMP\": \"recorded_time\", \"RESULT_VAL\": \"urine_output\"})\n",
    "# data type change\n",
    "urine_output[\"recorded_time\"] = pd.to_datetime(urine_output[\"recorded_time\"], format = \"%m/%d/%Y %H:%M:%S\")\n",
    "\n",
    "urine_output= urine_output[[\"csn\", \"recorded_time\", \"urine_output\"]]\n",
    "\n",
    "urine_output.to_csv(\"urine_output2021.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a07cab-4511-4d32-a82c-c67325ed3906",
   "metadata": {},
   "source": [
    "## 8. Mechanical Ventillation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7fdde908-aef8-4b58-b71d-b7c6516080a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing: 3:   1%|          | 3/312 [00:01<03:05,  1.66it/s]\n",
      "extraction complete\n"
     ]
    }
   ],
   "source": [
    "# specify directory\n",
    "vent_dir = [\"/labs/kamaleswaranlab/MODS/Data/Emory_Data/em_data/2021/CJSEPSIS_VENT_2021.dsv\"]\n",
    "\n",
    "fetch_cols = [\"pat_id\", \"csn\", \"recorded_time\", \"vent_start_time\", \"vent_stop_time\", \"vent_rate_set\", \"vent_tidal_rate_set\", \"vent_tidal_rate_exhaled\" , \"peep\", \"fio2\"]\n",
    "\n",
    "total_vent = import_dsv(directories = vent_dir, fetch_cols = fetch_cols, csns = csns)\n",
    "\n",
    "total_vent = total_vent.rename(columns = {\"fio2\": \"vent_fio2\"})\n",
    "\n",
    "total_vent[\"vent_start_time\"] = pd.to_datetime(total_vent[\"vent_start_time\"], format = \"%m/%d/%Y %H:%M:%S\")\n",
    "total_vent[\"recorded_time\"] = pd.to_datetime(total_vent[\"recorded_time\"], format = \"%m/%d/%Y %H:%M:%S\")\n",
    "total_vent[\"vent_stop_time\"] = pd.to_datetime(total_vent[\"vent_stop_time\"], format = \"%m/%d/%Y %H:%M:%S\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fad43593-885b-4335-b714-0d972264c5aa",
   "metadata": {},
   "source": [
    "### 8.1 MV Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4b77db96-b727-49b9-b627-b69762b57936",
   "metadata": {},
   "outputs": [],
   "source": [
    "c_vent = total_vent[~total_vent[\"vent_start_time\"].isna()].copy()\n",
    "\n",
    "c_vent = c_vent.sort_values(by = \"recorded_time\")\n",
    "v_start = c_vent.groupby(by = [\"pat_id\", \"csn\"]).first().reset_index()\n",
    "v_start = v_start[[\"pat_id\", \"csn\", \"recorded_time\"]].rename(columns = {\"recorded_time\": \"vent_start_time\"})\n",
    "v_stop = c_vent.groupby(by = [\"pat_id\", \"csn\"]).last().reset_index()\n",
    "v_stop = v_stop[[\"pat_id\", \"csn\", \"recorded_time\"]].rename(columns = {\"recorded_time\": \"vent_stop_time\"})\n",
    "\n",
    "new_vent = c_vent.drop([\"vent_start_time\", \"vent_stop_time\"], axis = 1)\n",
    "new_vent = new_vent.merge(v_start, on = [\"pat_id\", \"csn\"], how = \"left\")\n",
    "new_vent = new_vent.merge(v_stop, on = [\"pat_id\", \"csn\"], how = \"left\")\n",
    "\n",
    "clean_vent = new_vent.copy()\n",
    "clean_vent = clean_vent[clean_vent.csn.isin(csns)]\n",
    "vent_values = [\"vent_rate_set\", \"vent_tidal_rate_set\", \"vent_tidal_rate_exhaled\", \"peep\", \"vent_fio2\"]\n",
    "clean_vent[vent_values] = clean_vent[vent_values].replace(r'\\>|\\<|\\%|\\/|\\s','',regex=True)\n",
    "\n",
    "for i in vent_values:\n",
    "    clean_vent[i] = pd.to_numeric(clean_vent[i], errors = \"coerce\")\n",
    "\n",
    "clean_vent = clean_vent[~clean_vent[vent_values].isna().all(axis = 1)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1eff4f98-ea03-425c-b732-e6b8b561ecfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_vent.to_csv(\"vent2021.csv\", index= False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66c5757e-6183-4a71-a324-487698a7fbce",
   "metadata": {},
   "source": [
    "## 9. Merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "636f1257-6753-438f-a110-623066c14845",
   "metadata": {},
   "outputs": [],
   "source": [
    "# will not print following columns due being PHI\n",
    "hide = [\"csn\", \"pat_id\", \"age\", \"is_Female\", \"is_asian\", \"is_white\", \"is_black\", \"is_other\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a117e177-f45f-45a9-92d3-dcafbecf8cc7",
   "metadata": {},
   "source": [
    "### 9.0 Read all CSVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f2534217-408a-4198-ad61-27ff8d2a7953",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converted\n",
      "converted\n",
      "converted\n"
     ]
    }
   ],
   "source": [
    "times = pd.read_csv('times2021.csv')\n",
    "time_cols = [\"ed_presentation_time\", \"hospital_admission_date_time\", \"hospital_discharge_date_time\"]\n",
    "for i in time_cols:\n",
    "    times[i] = pd.to_datetime(times[i])\n",
    "    print(\"converted\")\n",
    "\n",
    "# few errors found with ed_pres\n",
    "times = times.drop([\"ed_presentation_time\"], axis = 1)\n",
    "times = times.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "47190ecc-457e-4acc-b4ad-e726d243b956",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converted\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>recorded_time</th>\n",
       "      <th>HR</th>\n",
       "      <th>O2Sat</th>\n",
       "      <th>Temp</th>\n",
       "      <th>SBP</th>\n",
       "      <th>DBP</th>\n",
       "      <th>MAP</th>\n",
       "      <th>Resp</th>\n",
       "      <th>EtCO2</th>\n",
       "      <th>o2_flow_rate</th>\n",
       "      <th>height_cm</th>\n",
       "      <th>daily_weight_kg</th>\n",
       "      <th>o2_supp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-03-08 16:11:00</td>\n",
       "      <td>84.0000</td>\n",
       "      <td>nan</td>\n",
       "      <td>36.8000</td>\n",
       "      <td>175.0000</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>21.0000</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-03-08 17:38:00</td>\n",
       "      <td>91.0000</td>\n",
       "      <td>99.0000</td>\n",
       "      <td>nan</td>\n",
       "      <td>146.0000</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>16.0000</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-03-08 19:52:00</td>\n",
       "      <td>84.0000</td>\n",
       "      <td>nan</td>\n",
       "      <td>36.7000</td>\n",
       "      <td>134.0000</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>18.0000</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-08-03 09:34:00</td>\n",
       "      <td>76.0000</td>\n",
       "      <td>nan</td>\n",
       "      <td>36.7000</td>\n",
       "      <td>134.0000</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>18.0000</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-11-29 16:02:00</td>\n",
       "      <td>87.0000</td>\n",
       "      <td>96.0000</td>\n",
       "      <td>36.8000</td>\n",
       "      <td>185.0000</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>18.0000</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        recorded_time      HR   O2Sat    Temp      SBP  DBP  MAP    Resp  \\\n",
       "0 2021-03-08 16:11:00 84.0000     nan 36.8000 175.0000  nan  nan 21.0000   \n",
       "1 2021-03-08 17:38:00 91.0000 99.0000     nan 146.0000  nan  nan 16.0000   \n",
       "2 2021-03-08 19:52:00 84.0000     nan 36.7000 134.0000  nan  nan 18.0000   \n",
       "3 2021-08-03 09:34:00 76.0000     nan 36.7000 134.0000  nan  nan 18.0000   \n",
       "4 2021-11-29 16:02:00 87.0000 96.0000 36.8000 185.0000  nan  nan 18.0000   \n",
       "\n",
       "   EtCO2  o2_flow_rate  height_cm  daily_weight_kg  o2_supp  \n",
       "0    nan           nan        nan              nan   0.0000  \n",
       "1    nan           nan        nan              nan   0.0000  \n",
       "2    nan           nan        nan              nan   0.0000  \n",
       "3    nan           nan        nan              nan   0.0000  \n",
       "4    nan           nan        nan              nan   0.0000  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vitals = pd.read_csv('vitals_2021.csv')\n",
    "time_cols = [\"recorded_time\"]\n",
    "for i in time_cols:\n",
    "    vitals[i] = pd.to_datetime(vitals[i])\n",
    "    print(\"converted\")\n",
    "\n",
    "vitals= vitals.drop([\"o2_device\"], axis = 1)\n",
    "\n",
    "vitals.loc[:, ~vitals.columns.isin(hide)].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ae8761ac-1c47-4cbd-bfcd-e6ec54f715cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converted\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>recorded_time</th>\n",
       "      <th>AST</th>\n",
       "      <th>Albumin</th>\n",
       "      <th>Alkalinephos</th>\n",
       "      <th>Anion_Gap</th>\n",
       "      <th>BUN</th>\n",
       "      <th>BaseExcess</th>\n",
       "      <th>Bilirubin_direct</th>\n",
       "      <th>Bilirubin_total</th>\n",
       "      <th>Calcium</th>\n",
       "      <th>Chloride</th>\n",
       "      <th>Creatinine</th>\n",
       "      <th>FiO2</th>\n",
       "      <th>Fibrinogen</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>HCO3</th>\n",
       "      <th>Hct</th>\n",
       "      <th>Hgb</th>\n",
       "      <th>INR</th>\n",
       "      <th>Lactate</th>\n",
       "      <th>MCH</th>\n",
       "      <th>MCHC</th>\n",
       "      <th>MPV</th>\n",
       "      <th>Magnesium</th>\n",
       "      <th>PT</th>\n",
       "      <th>PTT</th>\n",
       "      <th>PaCO2</th>\n",
       "      <th>PaO2</th>\n",
       "      <th>Phosphate</th>\n",
       "      <th>Phosphorus</th>\n",
       "      <th>Platelets</th>\n",
       "      <th>Potassium</th>\n",
       "      <th>Protein</th>\n",
       "      <th>RBC</th>\n",
       "      <th>RDW-CV</th>\n",
       "      <th>RDW-SD</th>\n",
       "      <th>SaO2</th>\n",
       "      <th>Sodium</th>\n",
       "      <th>TroponinI</th>\n",
       "      <th>WBC</th>\n",
       "      <th>pH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-06-20 20:17:00</td>\n",
       "      <td>18.0000</td>\n",
       "      <td>4.1000</td>\n",
       "      <td>64.0000</td>\n",
       "      <td>nan</td>\n",
       "      <td>21.0000</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>9.3000</td>\n",
       "      <td>107.0000</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>40.1000</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>9.1000</td>\n",
       "      <td>1.9000</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>206.0000</td>\n",
       "      <td>nan</td>\n",
       "      <td>7.1000</td>\n",
       "      <td>4.1300</td>\n",
       "      <td>12.7000</td>\n",
       "      <td>45.0000</td>\n",
       "      <td>nan</td>\n",
       "      <td>138.0000</td>\n",
       "      <td>nan</td>\n",
       "      <td>3.6000</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-04-15 15:14:00</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>7.3000</td>\n",
       "      <td>102.0000</td>\n",
       "      <td>0.4800</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>110.0000</td>\n",
       "      <td>nan</td>\n",
       "      <td>32.9000</td>\n",
       "      <td>10.8000</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>32.8000</td>\n",
       "      <td>10.3000</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>257.0000</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>3.6100</td>\n",
       "      <td>12.5000</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>139.0000</td>\n",
       "      <td>nan</td>\n",
       "      <td>9.2000</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-04-15 18:13:00</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>10.0000</td>\n",
       "      <td>11.0000</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>7.6000</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.4700</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>119.0000</td>\n",
       "      <td>nan</td>\n",
       "      <td>33.0000</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>273.0000</td>\n",
       "      <td>3.4000</td>\n",
       "      <td>nan</td>\n",
       "      <td>3.6300</td>\n",
       "      <td>12.6000</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-04-16 00:37:00</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>47.0000</td>\n",
       "      <td>nan</td>\n",
       "      <td>10.0000</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.8000</td>\n",
       "      <td>8.0000</td>\n",
       "      <td>99.0000</td>\n",
       "      <td>0.5300</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>113.0000</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>3.6000</td>\n",
       "      <td>5.4000</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>136.0000</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-05-22 18:48:00</td>\n",
       "      <td>nan</td>\n",
       "      <td>3.8000</td>\n",
       "      <td>94.0000</td>\n",
       "      <td>9.0000</td>\n",
       "      <td>10.0000</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.3000</td>\n",
       "      <td>nan</td>\n",
       "      <td>95.0000</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>27.9000</td>\n",
       "      <td>nan</td>\n",
       "      <td>8.5000</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>4.5000</td>\n",
       "      <td>7.2000</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>14.2000</td>\n",
       "      <td>45.4000</td>\n",
       "      <td>nan</td>\n",
       "      <td>130.0000</td>\n",
       "      <td>nan</td>\n",
       "      <td>5.4000</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        recorded_time     AST  Albumin  Alkalinephos  Anion_Gap     BUN  \\\n",
       "0 2021-06-20 20:17:00 18.0000   4.1000       64.0000        nan 21.0000   \n",
       "1 2021-04-15 15:14:00     nan      nan           nan        nan     nan   \n",
       "2 2021-04-15 18:13:00     nan      nan           nan    10.0000 11.0000   \n",
       "3 2021-04-16 00:37:00     nan      nan       47.0000        nan 10.0000   \n",
       "4 2021-05-22 18:48:00     nan   3.8000       94.0000     9.0000 10.0000   \n",
       "\n",
       "   BaseExcess  Bilirubin_direct  Bilirubin_total  Calcium  Chloride  \\\n",
       "0         nan               nan           0.4000   9.3000  107.0000   \n",
       "1         nan               nan              nan   7.3000  102.0000   \n",
       "2         nan               nan              nan   7.6000       nan   \n",
       "3         nan               nan           0.8000   8.0000   99.0000   \n",
       "4         nan               nan           0.3000      nan   95.0000   \n",
       "\n",
       "   Creatinine  FiO2  Fibrinogen  Glucose  HCO3     Hct     Hgb  INR  Lactate  \\\n",
       "0         nan   nan         nan      nan   nan 40.1000     nan  nan      nan   \n",
       "1      0.4800   nan         nan 110.0000   nan 32.9000 10.8000  nan      nan   \n",
       "2      0.4700   nan         nan 119.0000   nan 33.0000     nan  nan      nan   \n",
       "3      0.5300   nan         nan 113.0000   nan     nan     nan  nan      nan   \n",
       "4         nan   nan         nan      nan   nan     nan     nan  nan      nan   \n",
       "\n",
       "      MCH    MCHC     MPV  Magnesium  PT  PTT  PaCO2  PaO2  Phosphate  \\\n",
       "0     nan     nan  9.1000     1.9000 nan  nan    nan   nan        nan   \n",
       "1     nan 32.8000 10.3000        nan nan  nan    nan   nan        nan   \n",
       "2 30.0000     nan     nan        nan nan  nan    nan   nan        nan   \n",
       "3     nan     nan     nan        nan nan  nan    nan   nan        nan   \n",
       "4 27.9000     nan  8.5000        nan nan  nan    nan   nan        nan   \n",
       "\n",
       "   Phosphorus  Platelets  Potassium  Protein    RBC  RDW-CV  RDW-SD  SaO2  \\\n",
       "0         nan   206.0000        nan   7.1000 4.1300 12.7000 45.0000   nan   \n",
       "1         nan   257.0000        nan      nan 3.6100 12.5000     nan   nan   \n",
       "2         nan   273.0000     3.4000      nan 3.6300 12.6000     nan   nan   \n",
       "3         nan        nan     3.6000   5.4000    nan     nan     nan   nan   \n",
       "4         nan        nan     4.5000   7.2000 4.0900 14.2000 45.4000   nan   \n",
       "\n",
       "    Sodium  TroponinI    WBC  pH  \n",
       "0 138.0000        nan 3.6000 nan  \n",
       "1 139.0000        nan 9.2000 nan  \n",
       "2      nan        nan    nan nan  \n",
       "3 136.0000        nan    nan nan  \n",
       "4 130.0000        nan 5.4000 nan  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labs = pd.read_csv('labs_2021.csv')\n",
    "labs_cols = [\"recorded_time\"]\n",
    "for i in time_cols:\n",
    "    labs[i] = pd.to_datetime(labs[i])\n",
    "    print(\"converted\")\n",
    "\n",
    "labs.loc[:, ~labs.columns.isin(hide)].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ca5622de-3839-4168-ba2c-4092ad132038",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>recorded_time</th>\n",
       "      <th>urine_output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-01-16 11:00:00</td>\n",
       "      <td>500.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-01-16 16:00:00</td>\n",
       "      <td>525.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-01-25 10:00:00</td>\n",
       "      <td>300.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-01-28 19:00:00</td>\n",
       "      <td>125.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-02-11 15:00:00</td>\n",
       "      <td>600.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        recorded_time  urine_output\n",
       "0 2021-01-16 11:00:00      500.0000\n",
       "1 2021-01-16 16:00:00      525.0000\n",
       "2 2021-01-25 10:00:00      300.0000\n",
       "3 2021-01-28 19:00:00      125.0000\n",
       "4 2021-02-11 15:00:00      600.0000"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urine_output = pd.read_csv(\"urine_output2021.csv\")\n",
    "urine_output[\"recorded_time\"] = pd.to_datetime(urine_output[\"recorded_time\"])\n",
    "\n",
    "urine_output.loc[:, ~urine_output.columns.isin(hide)].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a1825dc4-6124-44fb-bc47-180ff4f748d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>recorded_time</th>\n",
       "      <th>gcs_total_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-03-08 16:33:00</td>\n",
       "      <td>15.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-10-01 20:50:00</td>\n",
       "      <td>15.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-10-03 19:24:00</td>\n",
       "      <td>15.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-12-04 18:07:00</td>\n",
       "      <td>15.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-12-04 23:46:00</td>\n",
       "      <td>15.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        recorded_time  gcs_total_score\n",
       "0 2021-03-08 16:33:00          15.0000\n",
       "1 2021-10-01 20:50:00          15.0000\n",
       "2 2021-10-03 19:24:00          15.0000\n",
       "3 2021-12-04 18:07:00          15.0000\n",
       "4 2021-12-04 23:46:00          15.0000"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gcs = pd.read_csv(\"GCS2021.csv\")\n",
    "gcs[\"recorded_time\"] = pd.to_datetime(gcs[\"recorded_time\"])\n",
    "gcs.loc[:, ~gcs.columns.isin(hide)].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "6f925f14-816e-4bfb-b9c7-c9d24776cf98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converted\n",
      "converted\n",
      "converted\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>recorded_time</th>\n",
       "      <th>vent_rate_set</th>\n",
       "      <th>vent_tidal_rate_set</th>\n",
       "      <th>vent_tidal_rate_exhaled</th>\n",
       "      <th>peep</th>\n",
       "      <th>vent_fio2</th>\n",
       "      <th>vent_start_time</th>\n",
       "      <th>vent_stop_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-01-01 02:14:00</td>\n",
       "      <td>20.0000</td>\n",
       "      <td>420.0000</td>\n",
       "      <td>370.0000</td>\n",
       "      <td>14.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>2021-01-01 02:14:00</td>\n",
       "      <td>2021-02-11 08:02:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-01-01 02:38:00</td>\n",
       "      <td>20.0000</td>\n",
       "      <td>420.0000</td>\n",
       "      <td>nan</td>\n",
       "      <td>14.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>2021-01-01 02:14:00</td>\n",
       "      <td>2021-02-11 08:02:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-01-01 06:14:00</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>16.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>2021-01-01 02:14:00</td>\n",
       "      <td>2021-02-11 08:02:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-01-01 08:00:00</td>\n",
       "      <td>20.0000</td>\n",
       "      <td>500.0000</td>\n",
       "      <td>409.0000</td>\n",
       "      <td>16.0000</td>\n",
       "      <td>0.8000</td>\n",
       "      <td>2021-01-01 02:14:00</td>\n",
       "      <td>2021-02-11 08:02:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-01-01 08:52:00</td>\n",
       "      <td>20.0000</td>\n",
       "      <td>500.0000</td>\n",
       "      <td>431.0000</td>\n",
       "      <td>16.0000</td>\n",
       "      <td>0.6000</td>\n",
       "      <td>2021-01-01 02:14:00</td>\n",
       "      <td>2021-02-11 08:02:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        recorded_time  vent_rate_set  vent_tidal_rate_set  \\\n",
       "0 2021-01-01 02:14:00        20.0000             420.0000   \n",
       "1 2021-01-01 02:38:00        20.0000             420.0000   \n",
       "2 2021-01-01 06:14:00            nan                  nan   \n",
       "3 2021-01-01 08:00:00        20.0000             500.0000   \n",
       "4 2021-01-01 08:52:00        20.0000             500.0000   \n",
       "\n",
       "   vent_tidal_rate_exhaled    peep  vent_fio2     vent_start_time  \\\n",
       "0                 370.0000 14.0000     1.0000 2021-01-01 02:14:00   \n",
       "1                      nan 14.0000     1.0000 2021-01-01 02:14:00   \n",
       "2                      nan 16.0000     1.0000 2021-01-01 02:14:00   \n",
       "3                 409.0000 16.0000     0.8000 2021-01-01 02:14:00   \n",
       "4                 431.0000 16.0000     0.6000 2021-01-01 02:14:00   \n",
       "\n",
       "       vent_stop_time  \n",
       "0 2021-02-11 08:02:00  \n",
       "1 2021-02-11 08:02:00  \n",
       "2 2021-02-11 08:02:00  \n",
       "3 2021-02-11 08:02:00  \n",
       "4 2021-02-11 08:02:00  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_vent = pd.read_csv(\"vent2021.csv\")\n",
    "\n",
    "time_cols = [\"recorded_time\", \"vent_start_time\",\"vent_stop_time\"]\n",
    "\n",
    "for i in time_cols:\n",
    "    clean_vent[i] = pd.to_datetime(clean_vent[i])\n",
    "    print(\"converted\")\n",
    "    \n",
    "clean_vent.loc[:, ~clean_vent.columns.isin(hide)].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6faf10b-607c-40c8-831b-01cdeee97153",
   "metadata": {},
   "source": [
    "### 9.1 Merge static features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f65b394d-cc28-4c96-a376-13b27fc1ec58",
   "metadata": {},
   "outputs": [],
   "source": [
    "times = times.drop_duplicates()\n",
    "stat = pd.merge(times, race_gender, on = \"pat_id\", how = \"right\")\n",
    "stat[\"discharge_to\"] = stat[\"discharge_to\"] == \"EXPIRED\"\n",
    "stat = stat.rename(columns = {\"discharge_to\": \"In_hospital_death\"})\n",
    "stat = stat.drop_duplicates()\n",
    "stat.to_csv(\"stat_2021.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da84792e-2cd2-40bb-9d48-778f6900986b",
   "metadata": {},
   "source": [
    "### Redefine CSNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "133c914a-748c-429e-9e32-f78ab312320a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of sepsis patients from 2021:  1734\n",
      "number of non-sepsis patients from 2021:  111353\n",
      "total number of encounters in 2021 cohort:  113087\n"
     ]
    }
   ],
   "source": [
    "sepsis_2021 = stat[~stat.t_sepsis3.isna()].csn.unique()\n",
    "nosepsis_2021 = stat[stat.t_sepsis3.isna()].csn.unique()\n",
    "np.save(\"sepsis_2021_csn.npy\", sepsis_2021)\n",
    "np.save(\"nosepsis_2021_csn.npy\", nosepsis_2021)\n",
    "\n",
    "csns = list(stat.csn.unique())\n",
    "print(\"number of sepsis patients from 2021: \", len(sepsis_2021))\n",
    "print(\"number of non-sepsis patients from 2021: \",len(nosepsis_2021))\n",
    "print(\"total number of encounters in 2021 cohort: \", len(csns))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e6fa115-e8c6-4056-9d35-a2d0ead89892",
   "metadata": {},
   "source": [
    "### 9.2 Merge longitudinal data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "640e6103-8892-48d5-aba2-80bcb1ab6801",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge vitals and labs on csn, pat_id, recorded_time w/ union\n",
    "\n",
    "vitals = vitals[vitals.csn.isin(csns)]\n",
    "labs =labs[labs.csn.isin(csns)]\n",
    "urine_output = urine_output[urine_output.csn.isin(csns)]\n",
    "gcs =gcs[gcs.csn.isin(csns)]\n",
    "new_vent = clean_vent[clean_vent.csn.isin(csns)]\n",
    "new_vent = new_vent[[\"csn\", \"pat_id\", \"vent_start_time\", \"vent_stop_time\"]].drop_duplicates()\n",
    "\n",
    "merged = pd.merge(vitals,labs,on = [\"csn\", \"pat_id\", \"recorded_time\"], how = \"outer\")\n",
    "\n",
    "merged = pd.merge(merged,urine_output,on = [\"csn\", \"recorded_time\"], how = \"outer\")\n",
    "\n",
    "merged = pd.merge(merged, gcs, on = [\"csn\", \"pat_id\", \"recorded_time\"], how = \"outer\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "614299cf-5085-4d28-906c-0837c72a5c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged.to_csv(\"longitudinal_2021.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "196a98ae-0905-492e-bc95-a15da2566a49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>recorded_time</th>\n",
       "      <th>HR</th>\n",
       "      <th>O2Sat</th>\n",
       "      <th>Temp</th>\n",
       "      <th>SBP</th>\n",
       "      <th>DBP</th>\n",
       "      <th>MAP</th>\n",
       "      <th>Resp</th>\n",
       "      <th>EtCO2</th>\n",
       "      <th>o2_flow_rate</th>\n",
       "      <th>height_cm</th>\n",
       "      <th>daily_weight_kg</th>\n",
       "      <th>o2_supp</th>\n",
       "      <th>AST</th>\n",
       "      <th>Albumin</th>\n",
       "      <th>Alkalinephos</th>\n",
       "      <th>Anion_Gap</th>\n",
       "      <th>BUN</th>\n",
       "      <th>BaseExcess</th>\n",
       "      <th>Bilirubin_direct</th>\n",
       "      <th>Bilirubin_total</th>\n",
       "      <th>Calcium</th>\n",
       "      <th>Chloride</th>\n",
       "      <th>Creatinine</th>\n",
       "      <th>FiO2</th>\n",
       "      <th>Fibrinogen</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>HCO3</th>\n",
       "      <th>Hct</th>\n",
       "      <th>Hgb</th>\n",
       "      <th>INR</th>\n",
       "      <th>Lactate</th>\n",
       "      <th>MCH</th>\n",
       "      <th>MCHC</th>\n",
       "      <th>MPV</th>\n",
       "      <th>Magnesium</th>\n",
       "      <th>PT</th>\n",
       "      <th>PTT</th>\n",
       "      <th>PaCO2</th>\n",
       "      <th>PaO2</th>\n",
       "      <th>Phosphate</th>\n",
       "      <th>Phosphorus</th>\n",
       "      <th>Platelets</th>\n",
       "      <th>Potassium</th>\n",
       "      <th>Protein</th>\n",
       "      <th>RBC</th>\n",
       "      <th>RDW-CV</th>\n",
       "      <th>RDW-SD</th>\n",
       "      <th>SaO2</th>\n",
       "      <th>Sodium</th>\n",
       "      <th>TroponinI</th>\n",
       "      <th>WBC</th>\n",
       "      <th>pH</th>\n",
       "      <th>urine_output</th>\n",
       "      <th>gcs_total_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-03-08 16:11:00</td>\n",
       "      <td>84.0000</td>\n",
       "      <td>nan</td>\n",
       "      <td>36.8000</td>\n",
       "      <td>175.0000</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>21.0000</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-03-08 17:38:00</td>\n",
       "      <td>91.0000</td>\n",
       "      <td>99.0000</td>\n",
       "      <td>nan</td>\n",
       "      <td>146.0000</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>16.0000</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-03-08 19:52:00</td>\n",
       "      <td>84.0000</td>\n",
       "      <td>nan</td>\n",
       "      <td>36.7000</td>\n",
       "      <td>134.0000</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>18.0000</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-08-03 09:34:00</td>\n",
       "      <td>76.0000</td>\n",
       "      <td>nan</td>\n",
       "      <td>36.7000</td>\n",
       "      <td>134.0000</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>18.0000</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-11-29 16:02:00</td>\n",
       "      <td>87.0000</td>\n",
       "      <td>96.0000</td>\n",
       "      <td>36.8000</td>\n",
       "      <td>185.0000</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>18.0000</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        recorded_time      HR   O2Sat    Temp      SBP  DBP  MAP    Resp  \\\n",
       "0 2021-03-08 16:11:00 84.0000     nan 36.8000 175.0000  nan  nan 21.0000   \n",
       "1 2021-03-08 17:38:00 91.0000 99.0000     nan 146.0000  nan  nan 16.0000   \n",
       "2 2021-03-08 19:52:00 84.0000     nan 36.7000 134.0000  nan  nan 18.0000   \n",
       "3 2021-08-03 09:34:00 76.0000     nan 36.7000 134.0000  nan  nan 18.0000   \n",
       "4 2021-11-29 16:02:00 87.0000 96.0000 36.8000 185.0000  nan  nan 18.0000   \n",
       "\n",
       "   EtCO2  o2_flow_rate  height_cm  daily_weight_kg  o2_supp  AST  Albumin  \\\n",
       "0    nan           nan        nan              nan   0.0000  nan      nan   \n",
       "1    nan           nan        nan              nan   0.0000  nan      nan   \n",
       "2    nan           nan        nan              nan   0.0000  nan      nan   \n",
       "3    nan           nan        nan              nan   0.0000  nan      nan   \n",
       "4    nan           nan        nan              nan   0.0000  nan      nan   \n",
       "\n",
       "   Alkalinephos  Anion_Gap  BUN  BaseExcess  Bilirubin_direct  \\\n",
       "0           nan        nan  nan         nan               nan   \n",
       "1           nan        nan  nan         nan               nan   \n",
       "2           nan        nan  nan         nan               nan   \n",
       "3           nan        nan  nan         nan               nan   \n",
       "4           nan        nan  nan         nan               nan   \n",
       "\n",
       "   Bilirubin_total  Calcium  Chloride  Creatinine  FiO2  Fibrinogen  Glucose  \\\n",
       "0              nan      nan       nan         nan   nan         nan      nan   \n",
       "1              nan      nan       nan         nan   nan         nan      nan   \n",
       "2              nan      nan       nan         nan   nan         nan      nan   \n",
       "3              nan      nan       nan         nan   nan         nan      nan   \n",
       "4              nan      nan       nan         nan   nan         nan      nan   \n",
       "\n",
       "   HCO3  Hct  Hgb  INR  Lactate  MCH  MCHC  MPV  Magnesium  PT  PTT  PaCO2  \\\n",
       "0   nan  nan  nan  nan      nan  nan   nan  nan        nan nan  nan    nan   \n",
       "1   nan  nan  nan  nan      nan  nan   nan  nan        nan nan  nan    nan   \n",
       "2   nan  nan  nan  nan      nan  nan   nan  nan        nan nan  nan    nan   \n",
       "3   nan  nan  nan  nan      nan  nan   nan  nan        nan nan  nan    nan   \n",
       "4   nan  nan  nan  nan      nan  nan   nan  nan        nan nan  nan    nan   \n",
       "\n",
       "   PaO2  Phosphate  Phosphorus  Platelets  Potassium  Protein  RBC  RDW-CV  \\\n",
       "0   nan        nan         nan        nan        nan      nan  nan     nan   \n",
       "1   nan        nan         nan        nan        nan      nan  nan     nan   \n",
       "2   nan        nan         nan        nan        nan      nan  nan     nan   \n",
       "3   nan        nan         nan        nan        nan      nan  nan     nan   \n",
       "4   nan        nan         nan        nan        nan      nan  nan     nan   \n",
       "\n",
       "   RDW-SD  SaO2  Sodium  TroponinI  WBC  pH  urine_output  gcs_total_score  \n",
       "0     nan   nan     nan        nan  nan nan           nan              nan  \n",
       "1     nan   nan     nan        nan  nan nan           nan              nan  \n",
       "2     nan   nan     nan        nan  nan nan           nan              nan  \n",
       "3     nan   nan     nan        nan  nan nan           nan              nan  \n",
       "4     nan   nan     nan        nan  nan nan           nan              nan  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged.loc[:, ~merged.columns.isin(hide)].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8dc4b89-6984-45d9-b08c-5a32e6582aeb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
